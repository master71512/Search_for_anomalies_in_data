# Отчет: Линейные модели машинного обучения

## Обзор

Проведено тестирование пяти моделей машинного обучения для детектирования мошеннических транзакций на датасете из ~1 млн операций. Целевая переменная: `isFraud` (0 = легальная, 1 = мошенничество).

**Разделение данных:** 70% обучение / 30% тестирование (stratified split)
**Размер тестового набора:** 314,573 примера (261,837 легальных, 52,736 мошеннических)

---

## Подготовка данных

### Удаленные признаки
- `Date` — не используется в линейных моделях
- `nameOrig` — идентификатор пользователя (никак не влияет на транзакции, все выполнены с разных ID)

### Кодирование признаков
- **One-Hot Encoding:** `type`, `Card Type`, `Exp Type`, `Gender`
- **Target Encoding:** `City` (986 уникальных значений)
  - Параметры: MIN_SAMPLES_LEAF=50, SMOOTHING=20
  - Использовано глобальное среднее для редких городов
- **Стандартизация:** `amount`, `oldbalanceOrg`, `newbalanceOrig` (StandardScaler)

### Итоговые признаки: 22 фичи

---

## Результаты моделей

### **Модель №1: Логистическая регрессия (базовая)**
```
Метрики:
- Accuracy: 86%
- Recall (полнота): 33% ⚠️ НИЗКИЙ
- Precision (прецизионность): 68%
- F1-score: 0.45
```

**Вывод:** Модель обнаруживает только 1/3 мошеннических операций. Слишком консервативна.

---

### **Модель №2: Логистическая регрессия с балансировкой классов** ✅ ЛУЧШАЯ ПО RECALL
```
Метрики:
- Accuracy: 65%
- Recall (полнота): 93% ✅ ХОРОШИЙ
- Precision (прецизионность): 32% ⚠️
- F1-score: 0.47
```

**Вывод:** Обнаруживает 93% мошенничества, но много ложных срабатываний (32% прецизионности). 3620 мошеннических операций не обнаружено.

**Важные коэффициенты признаков:**
| Признак | Коэффициент |
|---------|------------|
| City_TargetEncoded | **+7.52** | ← Города с высоким уровнем фрода ЖЕСТКО повышают риск
| type_TRANSFER | **+2.33** | ← Переводы → мошенничество
| type_PAYMENT | **-2.69** | ← Платежи → легальные операции
| newbalanceOrig | **-0.94** | ← Низкий финальный баланс → мошенничество
| oldbalanceOrg | **-0.93** | ← Низкий начальный баланс → мошенничество
| type_DEBIT | **-1.56** | ← Дебеты → легальные операции

---

### **Модель №3: Decision Tree CART (без балансировки)**
```
Метрики:
- Accuracy: 87%
- Recall: 33%
- Precision: 74%
- F1-score: 0.46
```

**Параметры:** max_depth=5, min_samples_split=20, min_samples_leaf=10

**Вывод:** Аналогично базовой логрегу — слишком консервативна.

---

### **Модель №4: Decision Tree CART (с балансировкой)**
```
Метрики:
- Accuracy: 75%
- Recall: 92%
- Precision: 39%
- F1-score: 0.55 ✅ ЛУЧШИЙ F1
```

**Параметры:** max_depth=15, min_samples_split=20, min_samples_leaf=10, class_weight='balanced'

**Вывод:** Лучший F1-score (0.55) среди всех моделей. Хороший баланс recall/precision (92% vs 39%).

---

### **Модель №5: Random Forest (100 деревьев)**
```
Метрики:
- Accuracy: 87%
- Recall: 32%
- Precision: 74%
- F1-score: 0.45
```

**Параметры:** n_estimators=100, max_depth=20, random_state=42

**Вывод:** Консервативна как базовая логрег, несмотря на n_estimators=100. Может требовать балансировки классов.

---

## Ключевые выводы

### Проблемы дисбаланса классов 
Датасет сильно несбалансирован:
- Легальных операций: 83.2% 
- Мошеннических: 16.8%

Модели "из коробки" (Модели 1, 3, 5) предпочитают минимизировать ошибки на большом классе, игнорируя мошенничество.

### Трейд-офф recall vs precision
- **Высокий recall (93%)** → много ложных срабатываний (32% precision) → раздражение клиентов
- **Высокий precision (74%)** → много пропущенных фродов (33% recall) → убытки банка

### Лучший баланс: Модель №4 (Decision Tree + балансировка)
- F1-score: **0.55** (лучший результат)
- Recall: **92%** (почти все фроды обнаружены)
- Precision: **39%** (приемлемо при балансировке классов)

### Информативные признаки
1. **City_TargetEncoded** (+7.52) — географический риск критичен
2. **type_TRANSFER** (+2.33) — переводы подозрительнее
3. **Баланс счета** — низкие балансы коррелируют с фродом

---

## Рекомендации для следующего этапа

1. **Нелинейные модели** (XGBoost, CatBoost, Neural Networks) — могут лучше уловить нелинейные зависимости
2. **Feature engineering:**
   - Взаимодействия признаков (amount × type, balance × gender)
   - Полиномиальные признаки
   - Временные фичи (день недели, часы пик)
3. **Оптимизация гиперпараметров** для моделей 4-5
4. **Ансамбли** — комбинация лучших моделей может улучшить результаты
5. **Пороговая оптимизация** — вместо вероятности 0.5 использовать адаптивный порог
6. **SMOTE/подвыборка** — синтетическое балансирование классов вместо class_weight